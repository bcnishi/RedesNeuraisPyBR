{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Il7H73VGJ2No"
   },
   "source": [
    "# Classificação do MNIST\n",
    "\n",
    "Vamos dar início à construção de um modelo capaz de classificar dígitos escritos a mão com mais de 90% de acurácia!!\n",
    "\n",
    "Relembrando o dataset, a imagem a seguir mostra alguns elementos pertencentes às dez classes do problema (dígitos de 0 a 9) <br>\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/MnistExamples.png/440px-MnistExamples.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LaoPWO9RhEq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yNikfN0J2Np"
   },
   "source": [
    "## Carregamento de dados.\n",
    "\n",
    "Para focar na implementação e treinamento da rede neural vamos utilizar o carregamento automático de datasets do **```torchvision```**. Vale muito conhecer o carregamento de dados do PyTorch, é bastante eficiente!\n",
    "\n",
    "Me cobrem de disponibilizar depois um tutorial de como carregar seus próprios dados ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWHd8oW15X2F"
   },
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST('.', train=True, \n",
    "                                       download=True,\n",
    "                                       transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "test_set = torchvision.datasets.MNIST('.', train=True, \n",
    "                                      download=False,\n",
    "                                      transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader  = DataLoader(test_set,\n",
    "                          batch_size=32,\n",
    "                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVFJWjBR6HC_"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,10, figsize=(14, 3))\n",
    "\n",
    "k = -1\n",
    "for data, label in test_loader:\n",
    "  k += 1\n",
    "  if k > 9: break\n",
    "\n",
    "  print(data.size(), label.size())\n",
    "  axs[k].imshow( data[0][0], cmap='gray' )\n",
    "  axs[k].set(title = str(label[0].item()), xticks=[], yticks=[] )\n",
    "\n",
    "plt.show()   \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGtnadiqJ2Nu"
   },
   "source": [
    "## Implementando nossa arquitetura!\n",
    "\n",
    "Defina a arquitetura da sua Rede Neural. O pacote torch.nn que contém as implementações de todas as camadas que serão usadas nessa parte (nn.Linear): \n",
    "\n",
    "- https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4oFGFAKJ2Nv"
   },
   "outputs": [],
   "source": [
    "class MinhaRede(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, n_classes):\n",
    "\n",
    "        super(MinhaRede, self).__init__()\n",
    "\n",
    "        '''\n",
    "        Exercício 1.1: Construa a sua rede neural. Ela deve ter entre 2\n",
    "        e 4 camadas escondidas e ir diminuindo o número de features (hidden size)\n",
    "        progressivamente ao longo essas camadas. Cada camada intermediária deve\n",
    "        receber o output da última camada. A primeira camada deve receber\n",
    "        input_size features e a última camada deve gerar n_classes features que\n",
    "        farão as predições entre as classes do MNIST. Adicione ativações ReLU\n",
    "        após todas as camadas nn.Linear, menos na última, que não deve ter\n",
    "        nenhuma ativação.\n",
    "        '''\n",
    "        # ###################################################\n",
    "        # # Neural Network architecture. 2~4 hidden layers. #\n",
    "        # ###################################################\n",
    "        # self.layer1 = # TO DO... Criar primeira camada linear.\n",
    "        # self.ativ1 = # TO DO... Criar ativação da primeira camada.\n",
    "        # self.layer2 = # TO DO... Criar segunda camada linear.\n",
    "        # self.ativ2 = # TO DO... Criar ativação da segunda camada.\n",
    "\n",
    "        # # TO DO... Criar outras camadas/ativações, se achar necessário\n",
    "\n",
    "    # Forward function.\n",
    "    def forward(self, x):\n",
    "\n",
    "        '''\n",
    "        Exercício 1.2: Alimente os dados para a camada da sua rede. Para\n",
    "        alimentar um dado x para uma certa camada self.camada_n:\n",
    "        saida = self.camada_n(x). \n",
    "        Lembre-se de verificar a dimensão do dado de entrada, ela deve estar\n",
    "        na forma (B, F), no nosso caso (32, 784).\n",
    "        '''\n",
    "        # ###################################################\n",
    "        # # Forwarding through all layers. ##################\n",
    "        # ###################################################\n",
    "        # out = # TO DO... Passar o input x sequencialmente pelas camadas da rede.\n",
    "\n",
    "        # Returning output.\n",
    "        return out # TO DO... Lembre-se de sempre retornar a saída da última camada.\n",
    "        \n",
    "# Instancing Network.\n",
    "input_size = 784 # Input size (number of features).\n",
    "n_classes = 10 # Number of classes.\n",
    "\n",
    "model = MinhaRede(input_size, n_classes).to(device) # GPU casting.\n",
    "\n",
    "# Printing NN.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ivyz5OiW-VS4"
   },
   "source": [
    "Teste aqui se a sua rede está criando a saída desejada (B, C)\n",
    "- B: `batch_size` \n",
    "- C: número de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tK2wGwsG-UOs"
   },
   "outputs": [],
   "source": [
    "k = -1\n",
    "for data, label in test_loader:\n",
    "  k += 1\n",
    "  if k > 2: break\n",
    "\n",
    "  data = data.to(device)\n",
    "  print(data.size())\n",
    "  saida = model(data)\n",
    "  print(saida.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlBTGdzPJ2N1"
   },
   "source": [
    "## Definindo um critério de qualidade (Loss)\n",
    "\n",
    "O primeiro passo é instanciar a função de perda de sua escolha. Trata-se de um problema de classificação com 3 classes, nesse caso a Cross Entropy é a função recomendada, que no PyTorch recebe o nome de ```nn.CrossEntropyLoss()```: https://pytorch.org/docs/stable/nn.html#crossentropyloss \n",
    "\n",
    "**Assim como a rede, as entradas e os rótulos, a função de perda também deve ser carregada na GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1WirBm_J2N2"
   },
   "outputs": [],
   "source": [
    "# Setting classification loss.\n",
    "'''\n",
    "Exercício 3: Defina uma loss function. Lembre-se de fazer o casting da loss para\n",
    "a GPU assim como fizemos na rede.\n",
    "'''\n",
    "criterion = # TO DO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOVXXfCiJ2Ny"
   },
   "source": [
    "## Instanciando o Otimizador\n",
    "\n",
    "> Pacote ```torch.optim```\n",
    "\n",
    "Mãos a obra! Vamos agora otimizar a nossa rede usando os algoritmos mais tradicionais da área. Para isso, a biblioteca ```torch.optim``` nos será bem útil, pois ela implementa os principais algoritmos de otimização de redes neurais.\n",
    "\n",
    "O primeiro passo é instanciar o otimizador. De acordo com o pacote ```optim```, basta chamar o otimizador escolhido, passando como parâmetro:\n",
    "* Os parâmetros da rede que será otimizada (```params = model.parameters()```)\n",
    "* A taxa de aprendizado (```lr```)\n",
    "* A regularização (```weight_decay```)\n",
    "\n",
    "A depender do otimizador, pode ser necessário alimentar outros parâmetros, mas esses quase sempre são obrigatórios!\n",
    "\n",
    "O $Pytorch$ tem várias opções de otimizadores, desde os mais simples como o SGD até adaptadores mais modernos com velocidades de aprendizado adaptáveis para cada parâmetro da rede (i.e. Adam, Adagrad, RSMProp...). Todos os otimizadores estão localizados no pacote torch.optim. \n",
    "\n",
    "Para mais informnações sobre o pacote, visite: <https://pytorch.org/docs/stable/optim.html>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhyopppRJ2Nz"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.0001 # TO DO se quiser, altere a learning rate\n",
    "regularizer = 0.00005 # L2 Normalization via weight decay.\n",
    "\n",
    "'''\n",
    "Exercício 2: Defina um otimizador. Utilize um otimizador mais poderoso \n",
    "como o Adam. Se quiser, experimente diferentes learning rates para o \n",
    "otimizador e observe como isso afeta a otimização da loss.\n",
    "'''\n",
    "optimizer = ## TO DO defina um otimizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9uC1yHfJ2N4"
   },
   "source": [
    "# Fluxo de Treinamento & Validação\n",
    "\n",
    "## Treinamento\n",
    "\n",
    "Passo a passo do fluxo de treinamento (uma época):\n",
    "* Iterar nos batches\n",
    "* Cast dos dados no dispositivo de hardware\n",
    "* Forward na rede e cálculo da loss\n",
    "* Zerar o gradiente do otimizador\n",
    "* Calcular o gradiente da variável loss\n",
    "* Atualizar dos pesos do modelo com o otimizador\n",
    "\n",
    "Esse conjunto de passos é responsável pelo processo iterativo de otimização de uma rede. **A validação** por outro lado, é apenas a aplicação da rede em dados nunca antes visto para estimar a qualidade do modelo no mundo real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04-4qarbJ2N5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Exercício 4: Complete o código da função a seguir para que ela implemente \n",
    "um fluxo de treinamento (descrição acima).\n",
    "'''\n",
    "\n",
    "def train(train_loader, net, epoch):\n",
    "\n",
    "  # Modo de treinamento\n",
    "  net.train()\n",
    "  \n",
    "  start = time.time()\n",
    "  \n",
    "  epoch_loss  = []\n",
    "\n",
    "  # Para cálculo da acurácia\n",
    "  pred_list, label_list = [], []\n",
    "\n",
    "  ## Iterando nos batches\n",
    "  for batch in train_loader:\n",
    "    \n",
    "    dado, rotulo = batch\n",
    "    \n",
    "    ## TO DO: Coloque os dados na GPU (variável device)\n",
    "    \n",
    "    \n",
    "    ## TO DO: realize o forward dos dados na rede\n",
    "    \n",
    "\n",
    "    ## TO DO: calcule a loss e dê append na lista epoch_loss \n",
    "    \n",
    "    \n",
    "    ## TO DO: calcule o gradiente da loss\n",
    "    \n",
    "\n",
    "    ## TO DO: Dê um passo de otimização\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Exercício 6: Quando terminar tudo e perceber que a sua loss está\n",
    "    reduzindo ao longo do treinamento, descomente todas as linhas a seguir\n",
    "    substituindo ypred por sua variável resposta do modelo e acompanhe \n",
    "    a acurácia da sua proposta de rede neural.\n",
    "    Faça isso também na função validate().\n",
    "    '''\n",
    "    # _, pred = torch.max(ypred, dim=1)\n",
    "    # pred_list.append(pred.cpu().numpy())\n",
    "    # label_list.append(rotulo.cpu().numpy())\n",
    "\n",
    "  epoch_loss = np.asarray(epoch_loss)\n",
    "\n",
    "\n",
    "  # acc = metrics.accuracy_score(np.asarray(label_list).ravel(),\n",
    "  #                                np.asarray(pred_list).ravel())\n",
    "  \n",
    "  end = time.time()\n",
    "  print('#################### Train ####################')\n",
    "  print('Epoch %d, Loss: %.4f +/- %.4f, Time: %.2f' % (epoch, epoch_loss.mean(), epoch_loss.std(), end-start))\n",
    "  # print('------- Acc: %.2f'%(acc*100))\n",
    "  \n",
    "  return epoch_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg4O4lArAMfR"
   },
   "source": [
    "## Validação\n",
    "\n",
    "Passo a passo do fluxo de validação (uma época):\n",
    "* Iterar nos batches\n",
    "* Cast dos dados no dispositivo de hardware\n",
    "* Forward na rede e cálculo da loss\n",
    "* ~~Zerar o gradiente do otimizador~~\n",
    "* ~~Calcular o gradiente da variável loss~~\n",
    "* ~~Atualizar dos pesos do modelo com o otimizador~~\n",
    "\n",
    "Para essa etapa, o PyTorch oferece dois artifícios:\n",
    "* ```model.eval()```: Impacta no *forward* da rede, informando as camadas caso seu comportamento mude entre fluxos (ex: dropout).\n",
    "* ```with torch.no_grad()```: Gerenciador de contexto que desabilita o cálculo e armazenamento de gradientes (economia de tempo e memória). Todo o código de validação deve ser executado dentro desse contexto.\n",
    "\n",
    "Exemplo de código para validação\n",
    "\n",
    "```python\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in test_loader:\n",
    "      # Código de validação\n",
    "```\n",
    "\n",
    "Existe o equivalente ao ```model.eval()``` para explicitar que a sua rede deve estar em modo de treino, é o ```model.train()```. Apesar de ser o padrão dos modelos, é boa prática definir também o modo de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6O62-6cAOP_"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Exercício 5: Complete o código da função a seguir para que ela implemente \n",
    "um fluxo de validação (descrição acima).\n",
    "'''\n",
    "\n",
    "def validate(test_loader, net, epoch):\n",
    "\n",
    "  # Modo de teste\n",
    "  net.eval()\n",
    "  \n",
    "  start = time.time()\n",
    "  \n",
    "  epoch_loss  = []\n",
    "\n",
    "  # Para cálculo da acurácia\n",
    "  pred_list, label_list = [], []\n",
    "  \n",
    "  with torch.no_grad(): \n",
    "     ## Iterando nos batches\n",
    "    for batch in test_loader:\n",
    "\n",
    "      dado, rotulo = batch\n",
    "\n",
    "      ## TO DO: Coloque os dados na GPU (variável device)\n",
    "\n",
    "\n",
    "      ## TO DO: realize o forward dos dados na rede\n",
    "\n",
    "\n",
    "      ## TO DO: calcule a loss e dê append na lista epoch_loss \n",
    "\n",
    "\n",
    "      # _, pred = torch.max(ypred, dim=1)\n",
    "      # pred_list.append(pred.cpu().numpy())\n",
    "      # label_list.append(rotulo.cpu().numpy())\n",
    "\n",
    "  epoch_loss = np.asarray(epoch_loss)\n",
    "\n",
    "  # acc = metrics.accuracy_score(np.asarray(label_list).ravel(),\n",
    "  #                                np.asarray(pred_list).ravel())\n",
    "  \n",
    "  end = time.time()\n",
    "  print('********** Validate **********')\n",
    "  print('Epoch %d, Loss: %.4f +/- %.4f, Time: %.2f' % (epoch, epoch_loss.mean(), epoch_loss.std(), end-start))\n",
    "  # print('------- Acc: %.2f\\n'%(acc*100))\n",
    "  \n",
    "  return epoch_loss.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8iWQH_grcP-"
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses = [], []\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "  \n",
    "  # Train\n",
    "  train_losses.append(train(train_loader, model, epoch))\n",
    "  \n",
    "  # Validate\n",
    "  test_losses.append(validate(test_loader, model, epoch))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MLP_Classification_MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
